main.py


import os
import functions_framework
from google.cloud import storage
from google.cloud import bigquery


# Environment variables

PROJECT_ID = os.environ.get('GCP_PROJECT') # Automatically set by Cloud Functions
BQ_DATASET = os.environ.get('BQ_DATASET')
BQ_TABLE = os.environ.get('BQ_TABLE')


@functions_framework.cloud_event

def load_csv_to_bigquery(cloud_event):   **** function end pint is what ever name use given in this should be taken : load_csv_to_bigquary 

    data = cloud_event.data

    bucket_name = data["bucket"]

    file_name = data["name"]


    print(f"Processing file: {file_name} from bucket: {bucket_name}")


    if not file_name.endswith('.csv'):

        print(f"Skipping non-CSV file: {file_name}")

        return


    # Construct the GCS URI for the file

    gcs_uri = f"gs://{bucket_name}/{file_name}"


    bigquery_client = bigquery.Client(project=PROJECT_ID)

    dataset_ref = bigquery_client.dataset(BQ_DATASET)

    table_ref = dataset_ref.table(BQ_TABLE)


    job_config = bigquery.LoadJobConfig(

        source_format=bigquery.SourceFormat.CSV,

        skip_leading_rows=1,  # Skip header row

        autodetect=True,      # Auto-detect schema from CSV header and data

        write_disposition=bigquery.WriteDisposition.WRITE_APPEND, # Append data to existing table

        # If you want to overwrite the table, use:

        # write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,

        # If the table doesn't exist, BigQuery will create it if autodetect is True and permissions allow.

    )


    try:

        # Start the load job

        load_job = bigquery_client.load_table_from_uri(

            gcs_uri,

            table_ref,

            job_config=job_config

        )


        print(f"Starting BigQuery load job {load_job.job_id} for file {file_name}")


        # Wait for the job to complete

        load_job.result()


        print(f"Job {load_job.job_id} finished. Loaded {load_job.output_rows} rows into {BQ_DATASET}.{BQ_TABLE}.")


    except Exception as e:

        print(f"Error loading data to BigQuery: {e}")






Requirements.txt


functions-framework==3.*
google-cloud-storage==2.*
google-cloud-bigquery==3.*





My_data.csv


fruit,color,count
apple,red,10
banana,yellow,15
grape,purple,20



